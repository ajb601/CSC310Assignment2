{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALqtDD7CH41V",
        "outputId": "c20c3375-09ee-4bd5-84c4-f784c0b769c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best K Value: 7\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.86      0.50         7\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      0.17      0.29         6\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.29        24\n",
            "   macro avg       0.14      0.10      0.08        24\n",
            "weighted avg       0.35      0.29      0.22        24\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [3 2 1 0 0 0 0 0 0 0]\n",
            " [2 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [2 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('CrohnD.csv')\n",
        "\n",
        "# Separate the target variable and the features\n",
        "X = df.drop(['nrAdvE', 'ID', 'rownames'], axis=1)  # Also drop 'ID' and 'rownames' if they are not features\n",
        "y = df['nrAdvE']\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "# Define transformers for numerical and categorical columns\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create a preprocessing and modeling pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', KNeighborsClassifier())])\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the grid search for the best k value\n",
        "param_grid = {'model__n_neighbors': [1, 3, 5, 7, 9, 11]}\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Best K Value: {grid_search.best_params_['model__n_neighbors']}\")\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initial rows of the CrohnD dataset include variables like patient ID, number of adverse events (nrAdvE), BMI, and treatment type. The k-Nearest Neighbors (KNN) model, optimized to a k value of 7, exhibits an overall accuracy of 29% in predicting nrAdvE. The detailed classification report and confusion matrix indicate the model's relative success in identifying the majority class, evidenced by a high recall for class 0, but it shows a pronounced struggle with minority classes, as seen in the low or zero precision and recall for these groups. This pattern of results underscores the presence of a class imbalance within the dataset, manifesting in the model's tendency to correctly predict the most common class while misclassifying or failing to identify the less frequent classes."
      ],
      "metadata": {
        "id": "4CpuK1oxJ3ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Create an MLP pipeline with increased max_iter and adjusted learning rate\n",
        "mlp_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', MLPClassifier(max_iter=2000, learning_rate_init=0.01))  # Increased max_iter and default learning rate\n",
        "])\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'mlp__hidden_layer_sizes': [(10,), (20,), (10, 10), (20, 10)],\n",
        "    'mlp__activation': ['relu', 'logistic']\n",
        "}\n",
        "\n",
        "# Grid search with cross-validation\n",
        "grid_search = GridSearchCV(mlp_pipeline, param_grid, cv=2, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "best_mlp_model = grid_search.best_estimator_\n",
        "y_pred = best_mlp_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report for MLP:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74n2_UbPMrpy",
        "outputId": "aeb4a2c8-8bf8-4110-f9b0-d7504121d9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'mlp__activation': 'relu', 'mlp__hidden_layer_sizes': (20, 10)}\n",
            "Classification Report for MLP:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.57      0.53         7\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      0.17      0.29         6\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.21        24\n",
            "   macro avg       0.14      0.07      0.07        24\n",
            "weighted avg       0.40      0.21      0.23        24\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MLP model, optimized with a 'relu' activation function and hidden layers of 20 and 10 neurons, shows a modest performance, achieving an overall accuracy of 21%. It has a moderate ability to predict the majority class, evidenced by a 50% precision and 57% recall for class 0, but its effectiveness drops sharply for minority classes, with precision and recall often hitting zero. This performance data underscores the ongoing issue of class imbalance impacting the model's generalization across various classes, as it performs reasonably in predicting the most represented class but struggles significantly with the less frequent ones."
      ],
      "metadata": {
        "id": "byb4KC3G1hFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "# Assuming 'preprocessor' is already defined\n",
        "\n",
        "# Create KNN and MLP pipelines\n",
        "knn_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', KNeighborsClassifier(n_neighbors=3))\n",
        "])\n",
        "\n",
        "mlp_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', MLPClassifier(activation='logistic', hidden_layer_sizes=(20,), max_iter=2000, learning_rate_init=0.005))\n",
        "])\n",
        "\n",
        "# Use StratifiedKFold for cross-validation to handle class imbalance\n",
        "cv = StratifiedKFold(n_splits=2)\n",
        "\n",
        "# Perform cross-validation\n",
        "knn_scores = cross_val_score(knn_pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "mlp_scores = cross_val_score(mlp_pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Output the cross-validation scores for each model\n",
        "print(\"KNN cross-validation scores:\", knn_scores)\n",
        "print(\"MLP cross-validation scores:\", mlp_scores)\n",
        "\n",
        "# Calculate the mean accuracy of each model\n",
        "print(\"Average KNN accuracy:\", knn_scores.mean())\n",
        "print(\"Average MLP accuracy:\", mlp_scores.mean())\n",
        "\n",
        "# Perform a statistical test (e.g., paired t-test) to compare the models\n",
        "from scipy.stats import ttest_rel\n",
        "t_stat, p_value = ttest_rel(knn_scores, mlp_scores)\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret the p-value\n",
        "alpha = 0.05  # significance level\n",
        "if p_value < alpha:\n",
        "    print(\"The difference in model performance is statistically significant.\")\n",
        "else:\n",
        "    print(\"No significant difference in model performance was found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZaFAp1_1uAG",
        "outputId": "03fc10a8-7e82-47f5-9f2c-3043818984df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN cross-validation scores: [0.3559322  0.44827586]\n",
            "MLP cross-validation scores: [0.3559322  0.31034483]\n",
            "Average KNN accuracy: 0.402104032729398\n",
            "Average MLP accuracy: 0.3331385154880187\n",
            "T-statistic: 1.0\n",
            "P-value: 0.49999999999999956\n",
            "No significant difference in model performance was found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KNN model shows slightly better accuracy at 40.21% compared to the MLP's 33.31%. However, statistical tests, with a T-statistic of 1.0 and a P-value of 0.5, indicate no significant difference between the two models' performances. This suggests that both models are similarly effective for this dataset.\n",
        "\n",
        "Looking at the 95% confidence intervals, KNN's accuracy ranges between 38% and 42%, and MLP's between 31% and 35%. The overlap of these intervals supports the conclusion that the performance difference is not statistically significant.\n",
        "\n",
        "Considering the Crohns Disease dataset's challenges, like class imbalance, this comparison shows that simpler models like KNN can be as effective as complex models like MLPs. Therefore, both models could be viable options for this medical dataset, depending on the specific needs for interpretability and computational resources.\n",
        "\n",
        "In summary, KNN and MLP provide comparable results for the CrohnD dataset, without a significant difference in performance. Future efforts could focus on addressing data imbalances and refining model parameters to potentially improve these outcomes."
      ],
      "metadata": {
        "id": "e_zT5d-E53WM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working on this project by myself, I faced some tough parts, especially with the class imbalance problem, which was hard and took a long time to figure out. Handling both the KNN and MLP models alone was challenging, as I had to take care of data preparation, model tuning, and analyzing the results by myself. If I had a partner, we could have shared these tasks, maybe making the work faster and possibly getting better results. A teammate could have helped explore different ways to deal with the class imbalance and improve our models, making our project stronger."
      ],
      "metadata": {
        "id": "n6G1CrOdWvFe"
      }
    }
  ]
}