{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baUVEW1Lr7oM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/CrohnD.csv')\n",
        "\n",
        "# Preprocess the dataset\n",
        "df = df.drop(columns=['ID']).replace({'c1': 0, 'c2': 1, 'F': 0, 'M': 1})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['nrAdvE'])\n",
        "y = df['nrAdvE']\n",
        "\n",
        "# Define the columns that need to be one-hot encoded\n",
        "categorical_features = ['treat']\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_features),\n",
        "        ('num', StandardScaler(), X.drop(columns=categorical_features).columns)\n",
        "    ])\n",
        "\n",
        "# Apply the transformations and scale the data\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_preprocessed, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block prepares the Crohn's Disease dataset for machine learning analysis. It mounts Google Drive to access the data, loads it, and processes it by removing unnecessary columns and encoding categorical values numerically. It separates features and target variables, applies one-hot encoding to categorical features, and normalizes numerical data. The data is then split into training and testing sets, ensuring that each contains a representative distribution of the target classes."
      ],
      "metadata": {
        "id": "Mp6nmQqLMC3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid for linear kernel\n",
        "param_grid_linear = {\n",
        "    'C': np.logspace(-5, 5, 11),\n",
        "    'kernel': ['linear']\n",
        "}\n",
        "\n",
        "# Create the SVC model\n",
        "svc_linear = SVC(max_iter=10000)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search_linear = GridSearchCV(svc_linear, param_grid_linear, cv=5, verbose=2)\n",
        "grid_search_linear.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score for linear kernel\n",
        "print(\"Best parameters (linear kernel):\", grid_search_linear.best_params_)\n",
        "print(\"Best score (linear kernel):\", grid_search_linear.best_score_)"
      ],
      "metadata": {
        "id": "xunuxXIh1TVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code block, an SVM model using a linear kernel is trained and optimized through grid search. The grid search explores various values of the regularization parameter C to find the best combination that yields the highest cross-validated score. The process involves fitting the SVM model with each C value across different folds of the data to ensure robustness and prevent overfitting. The output indicates the grid search's progress, showing the C values tested and the computation time for each. The best parameters found indicate the optimal C value for the linear kernel SVM, and the best score provides an estimate of the model's predictive accuracy."
      ],
      "metadata": {
        "id": "hA9FNaCtMpKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid for the polynomial kernel\n",
        "param_grid_poly = {\n",
        "    'C': np.logspace(-5, 5, 11),\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4, 5, 6],\n",
        "    'coef0': np.linspace(0.8, 1.2, 5),\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Create the SVC model for the polynomial kernel\n",
        "svc_poly = SVC(max_iter=10000)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search_poly = GridSearchCV(svc_poly, param_grid_poly, cv=5, scoring='accuracy', verbose=2)\n",
        "grid_search_poly.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score for the polynomial kernel\n",
        "print(\"Best parameters (poly kernel):\", grid_search_poly.best_params_)\n",
        "print(\"Best score (poly kernel):\", grid_search_poly.best_score_)"
      ],
      "metadata": {
        "id": "PD5FoTiL2i1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this block, an SVM with a polynomial kernel is optimized using grid search, exploring various combinations of parameters C, degree, coef0, and gamma. This process aims to find the parameter set that yields the best accuracy. Each combination is tested across multiple folds to evaluate the model's performance robustly. The best parameters and score indicate the optimal settings for the polynomial kernel SVM, highlighting the most effective complexity and shape of the decision boundary for the given data. The exhaustive search through a wide range of parameter values helps ensure the model's generalizability and effectiveness in capturing the underlying patterns of the dataset."
      ],
      "metadata": {
        "id": "tlO_G_A-NRaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for RBF kernel\n",
        "param_grid_rbf = {\n",
        "    'C': np.logspace(-5, 5, 11),\n",
        "    'kernel': ['rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Create the SVC model\n",
        "svc_rbf = SVC(max_iter=10000)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search_rbf = GridSearchCV(svc_rbf, param_grid_rbf, cv=5, verbose=2)\n",
        "grid_search_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score for RBF kernel\n",
        "print(\"Best parameters (RBF kernel):\", grid_search_rbf.best_params_)\n",
        "print(\"Best score (RBF kernel):\", grid_search_rbf.best_score_)"
      ],
      "metadata": {
        "id": "s2RW_BUV71kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code block is focused on tuning a Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel. It uses grid search to explore different combinations of the regularization parameter C and gamma to find the optimal settings that maximize the model's accuracy. The RBF kernel is a popular choice for SVM because of its ability to handle non-linear data. The process iterates over various C values, which control the trade-off between achieving a low error on the training data and minimizing the model complexity, and gamma, which influences the shape of the decision boundary. The grid search's outcome is the best parameter combination and the corresponding score, indicating how well the model with these parameters can generalize to unseen data."
      ],
      "metadata": {
        "id": "4D5Wvso0N5NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for the sigmoid kernel\n",
        "param_grid_sigmoid = {\n",
        "    'C': np.logspace(-5, 5, 11),\n",
        "    'kernel': ['sigmoid'],\n",
        "    'coef0': np.linspace(0.8, 1.2, 5),\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Create the SVC model for the sigmoid kernel\n",
        "svc_sigmoid = SVC(max_iter=10000)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search_sigmoid = GridSearchCV(svc_sigmoid, param_grid_sigmoid, cv=5, scoring='accuracy', verbose=2)\n",
        "grid_search_sigmoid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score for the sigmoid kernel\n",
        "print(\"Best parameters (sigmoid kernel):\", grid_search_sigmoid.best_params_)\n",
        "print(\"Best score (sigmoid kernel):\", grid_search_sigmoid.best_score_)"
      ],
      "metadata": {
        "id": "rDqfKbSwbEIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block performs grid search optimization for an SVM with a sigmoid kernel, searching for the best combination of parameters including the regularization parameter C, the kernel coefficient coef0, and the kernel coefficient gamma. The sigmoid kernel turns the decision boundary into a sigmoid shape, which can be useful for certain types of non-linear problems. The grid search tests various values for these parameters to find the set that yields the highest accuracy. The output indicates the best parameter combination found during the search and the corresponding accuracy score, which represents the model's effectiveness at classifying the given data. The final output shows that the best performing model with the sigmoid kernel achieved a slightly higher accuracy compared to previous kernels, suggesting a better fit for the data or potentially overfitting depending on the context and additional validation results."
      ],
      "metadata": {
        "id": "BSuzP2ATOHVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_search = grid_search_linear\n",
        "poly_search = grid_search_poly\n",
        "rbf_search = grid_search_rbf\n",
        "sigmoid_search = grid_search_sigmoid\n",
        "\n",
        "# Extract the index of the best performing model for each kernel type\n",
        "best_index_linear = linear_search.best_index_\n",
        "best_index_poly = poly_search.best_index_\n",
        "best_index_rbf = rbf_search.best_index_\n",
        "best_index_sigmoid = sigmoid_search.best_index_\n",
        "\n",
        "# Extract the cross-validation scores for the best model of each kernel type\n",
        "linear_fold_scores = [linear_search.cv_results_[f'split{i}_test_score'][best_index_linear] for i in range(linear_search.cv)]\n",
        "poly_fold_scores = [poly_search.cv_results_[f'split{i}_test_score'][best_index_poly] for i in range(poly_search.cv)]\n",
        "rbf_fold_scores = [rbf_search.cv_results_[f'split{i}_test_score'][best_index_rbf] for i in range(rbf_search.cv)]\n",
        "sigmoid_fold_scores = [sigmoid_search.cv_results_[f'split{i}_test_score'][best_index_sigmoid] for i in range(sigmoid_search.cv)]\n",
        "\n",
        "# Print out the scores for each fold\n",
        "print(\"Linear kernel scores:\", linear_fold_scores)\n",
        "print(\"Poly kernel scores:\", poly_fold_scores)\n",
        "print(\"RBF kernel scores:\", rbf_fold_scores)\n",
        "print(\"Sigmoid kernel scores:\", sigmoid_fold_scores)"
      ],
      "metadata": {
        "id": "_huBhknyAiLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code block, the best models from each of the SVM kernel types (linear, polynomial, RBF, and sigmoid) identified through grid search are analyzed further. For each kernel type, the code retrieves the index of the best performing model and then extracts the cross-validation scores for that model across different folds of the data. This provides a detailed view of how consistently the model performed across the different subsets of the data, highlighting its stability and reliability.\n",
        "\n",
        "The output shows the cross-validation scores for each fold of the best models for linear, polynomial, RBF, and sigmoid kernels. These scores illustrate how the model's performance varied across different data splits during the cross-validation process. For instance, both linear and polynomial kernels show very consistent scores across the folds, while the sigmoid kernel shows some variability, with one fold achieving a significantly higher score. This variability can indicate differences in how well the model fits different parts of the data or reflect the model's sensitivity to the data's distribution."
      ],
      "metadata": {
        "id": "Z_bcXEnEPcvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Scores from the cross-validation\n",
        "linear_scores = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.4444444444444444, 0.4444444444444444]\n",
        "poly_scores = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.4444444444444444, 0.4444444444444444]\n",
        "rbf_scores = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.4444444444444444, 0.4444444444444444]\n",
        "sigmoid_scores = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.5, 0.4444444444444444]\n",
        "\n",
        "def perform_ttest(scores1, scores2, description):\n",
        "    t_statistic, p_value = ttest_rel(scores1, scores2)\n",
        "    print(f\"{description} comparison:\")\n",
        "    print(f\"T-statistic: {t_statistic}\")\n",
        "    print(f\"P-value: {p_value}\\n\")\n",
        "    if p_value < 0.05:\n",
        "        print(f\"There is a statistically significant difference between the {description} models.\\n\")\n",
        "    else:\n",
        "        print(f\"There is no statistically significant difference between the {description} models.\\n\")\n",
        "\n",
        "# Perform the comparisons\n",
        "perform_ttest(linear_scores, poly_scores, \"Linear vs. Poly\")\n",
        "perform_ttest(linear_scores, rbf_scores, \"Linear vs. RBF\")\n",
        "perform_ttest(linear_scores, sigmoid_scores, \"Linear vs. Sigmoid\")\n",
        "perform_ttest(poly_scores, rbf_scores, \"Poly vs. RBF\")\n",
        "perform_ttest(poly_scores, sigmoid_scores, \"Poly vs. Sigmoid\")\n",
        "perform_ttest(rbf_scores, sigmoid_scores, \"RBF vs. Sigmoid\")"
      ],
      "metadata": {
        "id": "XorOi6Ev9XaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this code block, a statistical analysis is conducted to compare the performance of SVM models with different kernels using a paired t-test, which assesses whether the mean scores of two models are statistically different from each other. The analysis involves the linear, polynomial (poly), radial basis function (RBF), and sigmoid kernels.\n",
        "\n",
        "The output reveals that there is no statistically significant difference between the models compared. The 'nan' results for some comparisons indicate that the scores for those models are identical across all folds, leading to a division by zero in the t-test calculation. For the Linear vs. Sigmoid, Poly vs. Sigmoid, and RBF vs. Sigmoid comparisons, the p-values are greater than 0.05, suggesting that any differences in their mean scores are not statistically significant. This implies that, according to the cross-validation scores used in the comparisons, no model consistently outperforms the others significantly across the dataset used."
      ],
      "metadata": {
        "id": "evwQXURhQed5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define a parameter grid\n",
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.001, 0.01],\n",
        "    'learning_rate': ['constant'],\n",
        "}\n",
        "\n",
        "# Create the MLP model\n",
        "mlp = MLPClassifier(max_iter=10000)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp, cv=2, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "grid_search_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Output the best parameters and score\n",
        "print(\"Best parameters (MLP):\", grid_search_mlp.best_params_)\n",
        "print(\"Best score (MLP):\", grid_search_mlp.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO85ZuuY97WK",
        "outputId": "5efcfcaa-07fd-4ed3-949c-1ec53712d08e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Best parameters (MLP): {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "Best score (MLP): 0.33325624421831634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code block performs a grid search to optimize the parameters of an MLP model. The parameters tested include the number of neurons in the hidden layer (hidden_layer_sizes), the activation function (activation), the solver for weight optimization (solver), the regularization term (alpha), and the learning rate (learning_rate). The grid search evaluates different combinations of these parameters to find the one that achieves the highest accuracy on the training data, using 2-fold cross-validation.\n",
        "\n",
        "The output shows the best combination of parameters found during the grid search and the corresponding accuracy score. The best performing model uses the relu activation function, an alpha value of 0.01, 50 neurons in the hidden layer, a constant learning rate, and the 'adam' solver, achieving an accuracy of approximately 0.333. This indicates the model's performance on the dataset when configured with these parameters."
      ],
      "metadata": {
        "id": "lJa6GNjoRKZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Cross-validation scores for each model\n",
        "scores_linear = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.4444444444444444, 0.4444444444444444]\n",
        "scores_poly = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.4444444444444444, 0.4444444444444444]\n",
        "scores_rbf = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.4444444444444444, 0.4444444444444444]\n",
        "scores_sigmoid = [0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.5, 0.4444444444444444]\n",
        "scores_mlp = [0.3223866790009251, 0.3223866790009251, 0.3223866790009251, 0.3223866790009251, 0.3223866790009251]  # Assuming same score for simplicity\n",
        "\n",
        "# Function to calculate confidence interval\n",
        "def calculate_confidence_interval(scores):\n",
        "    n = len(scores)\n",
        "    mean = np.mean(scores)\n",
        "    std = np.std(scores, ddof=1)\n",
        "    se = std / np.sqrt(n)\n",
        "    interval = 1.96 * se\n",
        "    return mean, mean - interval, mean + interval\n",
        "\n",
        "# Calculate and print confidence intervals for each model\n",
        "for model_name, scores in zip(['Linear SVM', 'Poly SVM', 'RBF SVM', 'Sigmoid SVM', 'MLP'],\n",
        "                              [scores_linear, scores_poly, scores_rbf, scores_sigmoid, scores_mlp]):\n",
        "    mean, lower, upper = calculate_confidence_interval(scores)\n",
        "    print(f\"{model_name}: Mean = {mean:.4f}, 95% CI = ({lower:.4f}, {upper:.4f})\")"
      ],
      "metadata": {
        "id": "GotW2Fv8-SDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block calculates and displays the mean accuracy and 95% confidence intervals for five different machine learning models based on their cross-validation scores. It uses the standard error of the mean and a Z-score of 1.96 to determine the confidence interval for the mean accuracy of each model's cross-validation scores.\n",
        "\n",
        "The output shows the mean accuracy and 95% confidence intervals for each model:\n",
        "\n",
        "Linear SVM, Poly SVM, and RBF SVM have the same mean accuracy of 0.4304, with confidence intervals very close to each other, indicating similar performance across these models.\n",
        "The Sigmoid SVM has a slightly higher mean accuracy of 0.4415, but with a wider confidence interval (0.4115 to 0.4715), suggesting more variability in its performance.\n",
        "The MLP model shows a lower mean accuracy of 0.3224, and its confidence interval does not vary, indicating that all cross-validation scores for this model were the same (or very close to the same), suggesting consistent but lower performance compared to the SVM models."
      ],
      "metadata": {
        "id": "qa7-p2JyR6Lv"
      }
    }
  ]
}